"""
The snakefile that runs hecatomb.

This snakefile automatically calls the snakefiles in [rules](rules) to figure out the path.

Rob Edwards, October 2020
"""


import os
import sys


"""
Summary:
    # Step 0: Preprocessing (Rule: 00_preprocessing.smk)
    # Step 1: Taxonomic Assignment (Rule: 01_taxonomic_assignment.smk)
    # Step 3: Compile Results (Rule: 02_compile_results.smk)
"""

if not config:
    sys.stderr.write("FATAL: Please define a config file using the --configfile command line option.\n")
    sys.stderr.write("examples are provided in the Git repo\n")
    sys.exit()

# Set base database directories
DBDIR = config['Paths']['Databases']

# Paths for our data. This is where we will read and put things
READDIR = config['Paths']['Reads']

# Base output directories
ASSEMBLY = config['Output']['ASSEMBLY']
QC = config['Output']['QC']
LOGS = config['Output']['LOGS']
STATS = config['Output']['STATS']
RESULTS = config['Output']['RESULTS']
TMPDIR = config['Paths']['Temp']
if not os.path.exists(TMPDIR):
    os.makedirs(TMPDIR, exist_ok=True)
    
# Database sub-directories
CONPATH = os.path.join(DBDIR, "contaminants")
HOST = config['Paths']['Host']
HOSTPATH = os.path.join(DBDIR, "host", HOST)

fatal_errors = False
fatal_messages = []

###################################################################
#                                                                 #
# Protein databases                                               #
#                                                                 #
###################################################################

# Base path for protein sequence reference databases
PROTPATH = os.path.join(DBDIR, "proteins")
if not os.path.exists(PROTPATH):
    fatal_messages.append("protein databases")
    fatal_errors = True

# Primary aa search database: The virus protein database, clustered at 99% with cd-hit and then compiled with mmseqs    
UNIVIRDB = os.path.join(PROTPATH, "uniprot_virusDB")
if not os.path.exists(UNIVIRDB):
    fatal_messages.append(UNIVIRDB)
    fatal_errors = True
    
# Secondary aa search database
UNIREF50VIR = os.path.join(PROTPATH, "UniRef50_Virus")
if not os.path.exists(UNIREF50VIR):
 fatal_messages.append(UNIREF50VIR)
 fatal_errors = True

# output directories for our amino acid searches
AA_OUT = os.path.join(RESULTS, "MMSEQS_AA_OUT")
#AA_OUT_CHECKED = os.path.join(RESULTS, "MMSEQS_AA_OUT_CHECKED")

###################################################################
#                                                                 #
# Uniprot databases and related information                       #
#                                                                 #
###################################################################

#URVPATH = os.path.join(PROTPATH, "uniref_plus_virus")
#URVDB = os.path.join(URVPATH, "uniref50_virus.db") # uniref50 + viruses database
#if not os.path.exists(URVDB):
#    fatal_messages.append(URVDB)
#    fatal_errors = True

# Nucleotide data
#NUCLPATH = os.path.join(DBDIR, "nucleotides")
#NTDB = os.path.join(NUCLPATH, "refseq_virus_nt_UniVec_masked", "nt.fnaDB")
#if not os.path.exists(NTDB):
#    fatal_messages.append(f"nucleotide database {NTDB}")
#    fatal_errors = True

#NT_OUT = os.path.join(RESULTS, "mmseqs_nt_out")
#if not os.path.exists(NT_OUT):
#    os.makedirs(NT_OUT)

#NT_CHECKED_OUT = os.path.join(RESULTS, "mmseqs_nt_checked_out")
#if not os.path.exists(NT_CHECKED_OUT):
#    os.makedirs(NT_CHECKED_OUT)

###################################################################
#                                                                 #
# Taxonomy databases and related information                      #
#                                                                 #
###################################################################

#PHAGE_LINEAGES = os.path.join(DBDIR, "phages", "phage_taxonomic_lineages.txt")
#if not os.path.exists(PHAGE_LINEAGES):
#    fatal_messages.append("phages/phage_taxonomic_lineages.txt")
#    fatal_errors = True

#TAXPATH  = os.path.join(DBDIR, "taxonomy")
#TAXTAX = os.path.join(TAXPATH, "taxonomizr_accessionTaxa.sql")
#if not os.path.exists(TAXTAX):
#    fatal_messages.append(f"taxonomizr database {TAXTAX}")
#    fatal_errors = True

# Bacterial virus masked database for section 07 mmseqs pviral check

#BVMDB = os.path.join(NUCLPATH, "bac_virus_masked", "nt.fnaDB")
#if not os.path.exists(BVMDB):
#    fatal_messages.append(BVMDB)
#    fatal_errors = True


###################################################################
#                                                                 #
# Fatal errors should all be resolved by the download databsaes   #
#                                                                 #
###################################################################

if fatal_errors:
    sys.stderr.write("""
**** FATAL ERRORS ****

We can't proceed because we can't find one or more of the databases.
You probably need to download the databases before you can continue.

Please use the snakefile: 
   download_databases.smk

To download and install all the databases.

Here are a list of the databases that are currently missing:
""")
    sys.stderr.write("\n".join(fatal_messages))
    sys.stderr.write("\n\n")
    sys.exit(5)

###################################################################
#                                                                 #
# Read the sequence files and parse the file names.               #
#                                                                 #
###################################################################

SAMPLES,EXTENSIONS = glob_wildcards(os.path.join(READDIR, '{sample}_R1{extensions}'))

if not EXTENSIONS:
    sys.stderr.write("""
        FATAL: We could not parse the sequence file names.
        We are expecting {sample}_R1{extension}, and so your files
        should contain the characters '_R1' in the fwd reads
        and '_R2' in the rev reads
        """)
    sys.exit()
# we just get the generic extension. This is changed in Step 1/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-02/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-0218-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile18-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile

file_extension = EXTENSIONS[0]
# a convenience so we don't need to use '{sample}_R1' all the time
PATTERN = '{sample}'
PATTERN_R1 = '{sample}_R1'
PATTERN_R2 = '{sample}_R2'

if len(SAMPLES) == 0:
    sys.stderr.write("FATAL: We could not detect any samples at all.\n")
    sys.stderr.write("You should complain to Rob\n")
    sys.exit()

include: "rules/00_preprocessing.smk",
include: "rules/01_taxonomic_assignment.smk",
#include: "rules/02_compile_results.smk"

rule all:
    input:
        ## Output files from 00_preprocessing.smk
        os.path.join(RESULTS, "seqtable_all.tsv"),
        os.path.join(RESULTS, "seqtable.fasta"),
        os.path.join(RESULTS, "seqtable.faidx"),
        os.path.join(RESULTS, "seqtable_properties.tsv"),
        ## Assembly out from 00_preprocessing.smk
        expand(os.path.join(ASSEMBLY, PATTERN_R1 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN_R2 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN, PATTERN + ".contigs.fa"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs_size_selected.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.stats"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs_size_selected.sketch"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "assembly.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary.stats"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary.sketch"),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".aln.sam.gz"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".umapped.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".cov_stats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".rpkm"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".statsfile"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".scafstats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_counts.tmp"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_TPM.tmp"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_TPM"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_TPM.final"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_cov.tmp"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_contig_counts.tsv"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING",  "contig_count_table.tsv"),
        ## Output file from 01_mmseqs_pviral_aa.smk
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_lca.tsv"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_report"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_tophit_report"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_tophit_aln"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_tophit_aln_sorted"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_lca.ids"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_tophit_aln_sorted.ids"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_unclassified.ids"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_classified.fasta"),
        os.path.join(AA_OUT, "MMSEQS_AA_OUT_unclassified.fasta"),
        os.path.join(AA_OUT, "mmseqs_primary_aa_search_summary.txt")

        

