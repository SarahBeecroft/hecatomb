"""
The snakefile that runs hecatomb.

This snakefile automatically calls the snakefiles in [rules](rules) to figure out the path.

Rob Edwards, October 2020
"""


import os
import sys


"""
Summary:
    # Step 0: Preprocessing (Rule: 00_preprocessing.smk)
    # Step 1: Taxonomic Assignment (Rule: 01_taxonomic_assignment.smk)
    # Step 3: Compile Results (Rule: 02_compile_results.smk)
"""

if not config:
    sys.stderr.write("FATAL: Please define a config file using the --configfile command line option.\n")
    sys.stderr.write("examples are provided in the Git repo\n")
    sys.exit()

# Set base database directories
DBDIR = config['Paths']['Databases']

# Paths for our data. This is where we will read and put things
READDIR = config['Paths']['Reads']

# Base output directories
ASSEMBLY = config['Output']['ASSEMBLY']
QC = config['Output']['QC']
LOGS = config['Output']['LOGS']
STATS = config['Output']['STATS']
RESULTS = config['Output']['RESULTS']
TMPDIR = config['Paths']['Temp']
if not os.path.exists(TMPDIR):
    os.makedirs(TMPDIR, exist_ok=True)
    
# Database sub-directories
CONPATH = os.path.join(DBDIR, "contaminants")
HOST = config['Paths']['Host']
HOSTPATH = os.path.join(DBDIR, "host", HOST)
TAX = os.path.join(DBDIR, "tax", "taxonomy")
TABLES = os.path.join(DBDIR, "tables")

fatal_errors = False
fatal_messages = []

###################################################################
#                                                                 #
# REFERENCE DATABASES                                             #
#                                                                 #
###################################################################

# Base path for protein sequence reference databases
PROTPATH = os.path.join(DBDIR, "proteins")
if not os.path.exists(PROTPATH):
    fatal_messages.append("protein databases")
    fatal_errors = True

# Primary aa search database:
# The virus protein database, clustered at 99% with cd-hit    
UNIVIRDB = os.path.join(PROTPATH, "uniprot_virusDB")
if not os.path.exists(UNIVIRDB):
    fatal_messages.append(UNIVIRDB)
    fatal_errors = True

# Secondary aa search database
# UniRef50 + primary aa search database
UNIREF50VIR = os.path.join(PROTPATH, "UniRef50_Virus")
if not os.path.exists(UNIREF50VIR):
 fatal_messages.append(UNIREF50VIR)
 fatal_errors = True

# output directories for our amino acid searches
PRIMARY_AA_OUT = os.path.join(RESULTS, "MMSEQS_AA_PRIMARY")
SECONDARY_AA_OUT = os.path.join(RESULTS, "MMSEQS_AA_SECONDARY")

# Nucleotide databases base path
NUCLPATH = os.path.join(DBDIR, "nt")

# The virus nucleotide database, clustered at 100% with linclust
NCBIVIRDB = os.path.join(NUCLPATH, "ncbi", "ncbi_virus_genbank_sequences", "tax_added")
if not os.path.exists(NCBIVIRDB):
 fatal_messages.append(NCBIVIRDB)
 fatal_errors = True
 
# Polymicrobial + plant + virus database
POLYMICRODB = os.path.join(NUCLPATH, "refseq", "polymicrobial_plant")
if not os.path.exists(POLYMICRODB):
   fatal_messages.append(f"nucleotide database {POLYMICRODB}")
   fatal_errors = True

# output directories for our amino acid searches
PRIMARY_NT_OUT = os.path.join(RESULTS, "PRIMARY_NT_OUT")
SECONDARY_NT_OUT = os.path.join(RESULTS, "SECONDARY_NT_OUT")

###################################################################
#                                                                 #
# Taxonomy databases and related information                      #
#                                                                 #
###################################################################

#PHAGE_LINEAGES = os.path.join(DBDIR, "phages", "phage_taxonomic_lineages.txt")
#if not os.path.exists(PHAGE_LINEAGES):
#    fatal_messages.append("phages/phage_taxonomic_lineages.txt")
#    fatal_errors = True

#TAXPATH  = os.path.join(DBDIR, "taxonomy")
#TAXTAX = os.path.join(TAXPATH, "taxonomizr_accessionTaxa.sql")
#if not os.path.exists(TAXTAX):
#    fatal_messages.append(f"taxonomizr database {TAXTAX}")
#    fatal_errors = True

# Bacterial virus masked database for section 07 mmseqs pviral check

#BVMDB = os.path.join(NUCLPATH, "bac_virus_masked", "nt.fnaDB")
#if not os.path.exists(BVMDB):
#    fatal_messages.append(BVMDB)
#    fatal_errors = True


###################################################################
#                                                                 #
# Fatal errors should all be resolved by the download databsaes   #
#                                                                 #
###################################################################

#if fatal_errors:
#    sys.stderr.write("""
#**** FATAL ERRORS ****

#We can't proceed because we can't find one or more of the databases.
#You probably need to download the databases before you can continue.

#Please use the snakefile: 
#   download_databases.smk

#To download and install all the databases.

#Here are a list of the databases that are currently missing:
#""")
#    sys.stderr.write("\n".join(fatal_messages))
#    sys.stderr.write("\n\n")
#    sys.exit(5)

###################################################################
#                                                                 #
# Read the sequence files and parse the file names.               #
#                                                                 #
###################################################################

SAMPLES,EXTENSIONS = glob_wildcards(os.path.join(READDIR, '{sample}_R1{extensions}'))

if not EXTENSIONS:
    sys.stderr.write("""
        FATAL: We could not parse the sequence file names.
        We are expecting {sample}_R1{extension}, and so your files
        should contain the characters '_R1' in the fwd reads
        and '_R2' in the rev reads
        """)
    sys.exit()
# we just get the generic extension. This is changed in Step 1/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-02/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-0218-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile18-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile

file_extension = EXTENSIONS[0]
# a convenience so we don't need to use '{sample}_R1' all the time
PATTERN = '{sample}'
PATTERN_R1 = '{sample}_R1'
PATTERN_R2 = '{sample}_R2'

if len(SAMPLES) == 0:
    sys.stderr.write("FATAL: We could not detect any samples at all.\n")
    sys.stderr.write("You should complain to Rob\n")
    sys.exit()

include: "rules/00_preprocessing.smk",
include: "rules/01_taxonomic_assignment.smk",
#include: "rules/02_compile_results.smk"

rule all:
    input:
        #### Output files from 00_preprocessing.smk
        os.path.join(RESULTS, "seqtable_all.tsv"),
        os.path.join(RESULTS, "seqtable.fasta"),
        os.path.join(RESULTS, "seqtable.faidx"),
        os.path.join(RESULTS, "seqtable_properties.tsv"),
        ## Assembly out from 00_preprocessing.smk
        expand(os.path.join(ASSEMBLY, PATTERN_R1 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN_R2 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN, PATTERN + ".contigs.fa"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs_size_selected.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.stats"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs_size_selected.sketch"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "assembly.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary.stats"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary.sketch"),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".aln.sam.gz"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".umapped.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".cov_stats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".rpkm"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".statsfile"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".scafstats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_counts.tmp"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_TPM.tmp"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_TPM"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_TPM.final"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_cov.tmp"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_contig_counts.tsv"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING",  "contig_count_table.tsv"),
        #### Output file from 01_taxonomic_assignment.smk
        ## Primary (virus protein database) translated (nt-to-aa) search
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_lca.tsv"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_report"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_report"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_aln"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_aln_sorted"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_lca.ids"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_aln_sorted.ids"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_unclassified.ids"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_classified.fasta"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_unclassified.fasta"),
        os.path.join(RESULTS, "SEARCH_SUMMARY", "MMSEQS_AA_PRIMARY_summary.txt"),
        os.path.join(RESULTS, "SEARCH_SUMMARY", "MMSEQS_AA_PRIMARY_virus_family_summary.txt"),
        os.path.join(RESULTS, "SEARCH_SUMMARY", "MMSEQS_AA_PRIMARY_incomplete_lineage.txt"),
        ## Secondary (likely viral to transkingdom database) translated (nt-to-aa) search
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_lca.tsv"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_report"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_tophit_report"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_tophit_aln"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_tophit_aln_sorted"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_lca.ids"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_lca_classified.ids"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_lca_unclassified.ids"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_classified.fasta"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_unclassified.fasta"),
        os.path.join(RESULTS, "SEARCH_SUMMARY", "MMSEQS_AA_SECONDARY_summary.txt"),
        os.path.join(RESULTS, "SEARCH_SUMMARY", "MMSEQS_AA_SECONDARY_virus_family_summary.txt"),
        os.path.join(SECONDARY_AA_OUT, "tophit.seq.ids"),
        os.path.join(SECONDARY_AA_OUT, "tophit.tax.ids"),
        os.path.join(SECONDARY_AA_OUT, "tophit.seq_tax.ids"),
        os.path.join(SECONDARY_AA_OUT, "tophit.lineage.vir"),
        os.path.join(SECONDARY_AA_OUT, "tophit.lineage.vir.reformated"),
        os.path.join(SECONDARY_AA_OUT, "tophit.vir.tsv"),
        os.path.join(SECONDARY_AA_OUT, "lca_virus_root.seq.ids"),
        os.path.join(SECONDARY_AA_OUT, "lca_virus_root.vir.tsv"),
        os.path.join(SECONDARY_AA_OUT, "lca_virus_root.nonvir.seq.ids"),
        os.path.join(SECONDARY_AA_OUT, "lca_unclass.seq.ids"),
        os.path.join(SECONDARY_AA_OUT, "lca_unclass.vir.tsv"),
        os.path.join(SECONDARY_AA_OUT, "lca_unclass.nonvir.seq.ids"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_lca_no_virus_root.tsv"),
        os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_lca.filtered.tsv"),
        os.path.join(SECONDARY_AA_OUT, "lca.filtered.seq.ids"),
        os.path.join(SECONDARY_AA_OUT, "lca.filtered.tax.ids"),
        os.path.join(SECONDARY_AA_OUT, "lca.filtered.seq_tax.ids"),
        os.path.join(SECONDARY_AA_OUT, "lca.filtered.lineage"),
        os.path.join(SECONDARY_AA_OUT, "lca.filtered.lineage.reformated"),
        os.path.join(SECONDARY_AA_OUT, "lca_aa.tsv"),
        os.path.join(SECONDARY_AA_OUT, "lca_concat_aa.tsv"),
        os.path.join(SECONDARY_AA_OUT, "aa_unannotated.ids"),
        os.path.join(SECONDARY_AA_OUT, "viroDB.headers"),
        os.path.join(SECONDARY_AA_OUT, "viroDB.ids"),
        os.path.join(SECONDARY_AA_OUT, "uniref.headers"),
        os.path.join(SECONDARY_AA_OUT, "uniref.ids"),
        os.path.join(SECONDARY_AA_OUT, "viroDB.proteins"),
        os.path.join(SECONDARY_AA_OUT, "viroDB.proteins.tsv"),
        os.path.join(SECONDARY_AA_OUT, "uniref.proteins"),
        os.path.join(SECONDARY_AA_OUT, "uniref.proteins.tsv"),
        os.path.join(SECONDARY_AA_OUT, "protein.annotations.tsv"),
        os.path.join(SECONDARY_AA_OUT, "lca_aa_final_protein_annotated.tsv"),
        os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_classified.fasta.ids"),
        os.path.join(PRIMARY_AA_OUT, "primary_AA_classified.tophit.aln"),
        os.path.join(PRIMARY_AA_OUT, "primary_AA_classified.tophit.aln.taxIDs"),
        os.path.join(PRIMARY_AA_OUT, "primary_AA_classified.tophit.aln.seq_taxIDs"),
        os.path.join(PRIMARY_AA_OUT, "primary_AA_classified.lineage"),
        os.path.join(PRIMARY_AA_OUT, "primary_AA_classified.lineage.reformated"),
        os.path.join(PRIMARY_AA_OUT, "primary_AA_family.summary"),
        os.path.join(PRIMARY_AA_OUT, "primary_AA_genus.summary"),
        os.path.join(PRIMARY_AA_OUT, "secondary_AA_order.summary"),
        os.path.join(PRIMARY_AA_OUT, "secondary_AA_family.summary"),
        os.path.join(PRIMARY_AA_OUT, "secondary_AA_genus.summary"),
        os.path.join(PRIMARY_AA_OUT, "secondary_AA_species.summary"),
        os.path.join(PRIMARY_AA_OUT, "order.compare"),
        os.path.join(PRIMARY_AA_OUT, "family.compare"),
        os.path.join(PRIMARY_AA_OUT, "genus.compare"),
        os.path.join(PRIMARY_AA_OUT, "species.compare"),
        os.path.join(PRIMARY_AA_OUT, "family.compare.baltimore")
        ## Output from untranslated (nt-to-nt) search against polymicrobial + plant database
        #os.path.join(PRIMARY_NT_OUT, "aa_unclassified.fasta")
        

