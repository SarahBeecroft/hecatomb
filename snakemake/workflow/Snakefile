"""
The snakefile that runs hecatomb.

This snakefile automatically calls the snakefiles in [rules](rules) to figure out the path.

Rob Edwards, October 2020
"""


import os
import sys


"""
Summary:
    # Step 1: Prinseq to clean and deduplicate sequences
    # Step 2: Remove 5' amplification primer
    # Step 3: Remove 3' read through contaminant (Reverse complement of amplification primer + 6 bases of the adapter)
    # Step 4: Remove remaining adapter
    # Step 5: PhiX Removal and vector contamination removal
    # Step 6: Host-removal
    # Step 7: Trim remaing low-quality bases
"""

if not config:
    sys.stderr.write("FATAL: Please define a config file using the --configfile command line option.\n")
    sys.stderr.write("examples are provided in the Git repo\n")
    sys.exit()

# set base database directories
DBDIR = config['Paths']['Databases']
HOST = config['Paths']['Host']

# paths for our specific databases
CONPATH = os.path.join(DBDIR, "contaminants")
HOSTPATH = os.path.join(DBDIR, "host", HOST)

# paths for our data. This is where we will read and put things
READDIR = config['Paths']['Reads']
QC = config['Output']['QC']
LOGS = config['Output']['LOGS']
STATS = config['Output']['STATS']
RESULTS = config['Output']['RESULTS']
TMPDIR = config['Paths']['Temp']
if not os.path.exists(TMPDIR):
    os.makedirs(TMPDIR, exist_ok=True)


fatal_errors = False
fatal_messages = []

# output directories for our amino acid searches
#AA_OUT  = os.path.join(RESULTS, "mmseqs_aa_out")
#AA_OUT_CHECKED  = os.path.join(RESULTS, "mmseqs_aa_checked_out")

# paths for our protein sequence reference databases
#PROTPATH = os.path.join(DBDIR, "proteins")
#if not os.path.exists(PROTPATH):
#    fatal_messages.append("protein databases")
#    fatal_errors = True

# The virus database, clustered at 99% with cd-hit and then compiled
# with mmseqs

#VIRDB = os.path.join(PROTPATH, "uniprot_virus_c99.db")
#if not os.path.exists(VIRDB):
#    fatal_messages.append(VIRDB)
#    fatal_errors = True

#PHAGE_LINEAGES = os.path.join(DBDIR, "phages", "phage_taxonomic_lineages.txt")
#if not os.path.exists(PHAGE_LINEAGES):
#    fatal_messages.append("phages/phage_taxonomic_lineages.txt")
#    fatal_errors = True

###################################################################
#                                                                 #
# Uniprot databases and related information                       #
#                                                                 #
###################################################################

#URVPATH = os.path.join(PROTPATH, "uniref_plus_virus")
#URVDB = os.path.join(URVPATH, "uniref50_virus.db") # uniref50 + viruses database
#if not os.path.exists(URVDB):
#    fatal_messages.append(URVDB)
#    fatal_errors = True

# Nucleotide data
#NUCLPATH = os.path.join(DBDIR, "nucleotides")
#NTDB = os.path.join(NUCLPATH, "refseq_virus_nt_UniVec_masked", "nt.fnaDB")
#if not os.path.exists(NTDB):
#    fatal_messages.append(f"nucleotide database {NTDB}")
#    fatal_errors = True

#NT_OUT = os.path.join(RESULTS, "mmseqs_nt_out")
#if not os.path.exists(NT_OUT):
#    os.makedirs(NT_OUT)

#NT_CHECKED_OUT = os.path.join(RESULTS, "mmseqs_nt_checked_out")
#if not os.path.exists(NT_CHECKED_OUT):
#    os.makedirs(NT_CHECKED_OUT)

###################################################################
#                                                                 #
# Taxonomy databases and related information                      #
#                                                                 #
###################################################################

#TAXPATH  = os.path.join(DBDIR, "taxonomy")
#TAXTAX = os.path.join(TAXPATH, "taxonomizr_accessionTaxa.sql")
#if not os.path.exists(TAXTAX):
#    fatal_messages.append(f"taxonomizr database {TAXTAX}")
#    fatal_errors = True

# Bacterial virus masked database for section 07 mmseqs pviral check

#BVMDB = os.path.join(NUCLPATH, "bac_virus_masked", "nt.fnaDB")
#if not os.path.exists(BVMDB):
#    fatal_messages.append(BVMDB)
#    fatal_errors = True

###################################################################
#                                                                 #
# The bacterial and host bbmap and bowtie2 indexes                #
#                                                                 #
###################################################################

# check to see if we have the right versions of the databases for
# either bowtie or bbmap (default)
#if config['Options']['use_bowtie']:
#    for bti in [BACBT2, HOSTBT2]:
#        if not os.path.exists(f"{bti}.1.bt2l") and not os.path.exists(f"{bti}.1.bt2"):
#            fatal_messages.append(f"bowtie2 indexes for {bti}")
#            fatal_errors = True

#    if not os.path.exists(os.path.join(CONPATH, "line_sine.1.bt2")):
#        fatal_messages.append("bowtie2 indexes for the line/sine database")
#        fatal_errors = True
#else:
#    if not os.path.exists(os.path.join(HOSTPATH, "ref")):
#        fatal_messages.append("host databases")
#        fatal_errors = True

###################################################################
#                                                                 #
# Fatal errors should all be resolved by the download databsaes   #
#                                                                 #
###################################################################

if fatal_errors:
    sys.stderr.write("""
**** FATAL ERRORS ****

We can't proceed because we can't find one or more of the databases.
You probably need to download the databases before you can continue.

Please use the snakefile: 
   download_databases.smk

To download and install all the databases.

Here are a list of the databases that are currently missing:
""")
    sys.stderr.write("\n".join(fatal_messages))
    sys.stderr.write("\n\n")
    sys.exit(5)

###################################################################
#                                                                 #
# Read the sequence files and parse the file names.               #
#                                                                 #
###################################################################

SAMPLES,EXTENSIONS = glob_wildcards(os.path.join(READDIR, '{sample}_R1{extensions}'))

if not EXTENSIONS:
    sys.stderr.write("""
        FATAL: We could not parse the sequence file names.
        We are expecting {sample}_R1{extension}, and so your files
        should contain the characters '_R1' in the fwd reads
        and '_R2' in the rev reads
        """)
    sys.exit()
# we just get the generic extension. This is changed in Step 1

file_extension = EXTENSIONS[0]
# a convenience so we don't need to use '{sample}_R1' all the time
PATTERN_R1 = '{sample}_R1'
PATTERN_R2 = '{sample}_R2'

if len(SAMPLES) == 0:
    sys.stderr.write("FATAL: We could not detect any samples at all.\n")
    sys.stderr.write("You should complain to Rob\n")
    sys.exit()

include: "rules/00_contaminant_removal.smk"
#include: "rules/02_cluster_count.smk"
#include: "rules/03_seqtable.smk"
#include: "rules/04_mmseqs_pviral_aa.smk"
#include: "rules/05_mmseqs_pviral_aa_check.smk"
#include: "rules/06_mmseqs_pviral_nt.smk"
#include: "rules/07_mmseqs_pviral_nt_check.smk"
#include: "rules/08_concatenate_results.smk"
  
rule all:
    input:
        # output of 00_contaminant_removal.smk
        #expand(os.path.join(QC, "HOST_REMOVED", PATTERN_R1 + ".all.fastq"), sample=SAMPLES),
        #expand(os.path.join(QC, "HOST_REMOVED", PATTERN_R2 + ".all.fastq"), sample=SAMPLES),
        expand(os.path.join(QC, "CLUSTERED", PATTERN_R1 + ".deduped.out.fastq"), sample=SAMPLES)
